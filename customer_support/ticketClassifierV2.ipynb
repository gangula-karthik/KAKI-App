{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "from spacy.util import minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/daaa/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ticketClassification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Technical issue Product setup I'm having an is...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Technical issue Peripheral compatibility I'm h...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Technical issue Network problem I'm facing a p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Billing inquiry Account access I'm having an i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Billing inquiry Data loss I'm having an issue ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  label\n",
       "0           0  Technical issue Product setup I'm having an is...      3\n",
       "1           1  Technical issue Peripheral compatibility I'm h...      3\n",
       "2           2  Technical issue Network problem I'm facing a p...      0\n",
       "3           3  Billing inquiry Account access I'm having an i...      0\n",
       "4           4  Billing inquiry Data loss I'm having an issue ...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Technical issue Product setup I'm having an is...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    2192\n",
       "3    2129\n",
       "2    2085\n",
       "0    2063\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts() # dataset is balanced :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df(df):\n",
    "    return df.apply(lambda row: (row['text'], {\"cats\": {row['label']: 1}}), axis=1).tolist()\n",
    "\n",
    "train_data = convert_df(train)\n",
    "test_data = convert_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n"
     ]
    }
   ],
   "source": [
    "from spacy.training import Example\n",
    "\n",
    "def convert_to_example(df):\n",
    "    examples = []\n",
    "    for text, annot in df:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, annot)\n",
    "        examples.append(example)\n",
    "    return examples\n",
    "\n",
    "train_data = convert_df(train)\n",
    "train_examples = convert_to_example(train_data)\n",
    "\n",
    "# Start training\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "for i in range(10):\n",
    "    losses = {}\n",
    "    batches = minibatch(train_examples, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        nlp.update(batch, sgd=optimizer, drop=0.2, losses=losses)\n",
    "    print(\"Losses\", losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.training.example.Example' object has no attribute 'cats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m predicted_label \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(doc\u001b[39m.\u001b[39mcats, key\u001b[39m=\u001b[39mdoc\u001b[39m.\u001b[39mcats\u001b[39m.\u001b[39mget)  \u001b[39m# Get the label with the highest score\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# Get the actual label\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m actual_label \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(example\u001b[39m.\u001b[39;49mcats, key\u001b[39m=\u001b[39mexample\u001b[39m.\u001b[39mannotation\u001b[39m.\u001b[39mcats\u001b[39m.\u001b[39mget)\n\u001b[1;32m     17\u001b[0m \u001b[39m# If the predicted label matches the actual label, increment correct_predictions\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m predicted_label \u001b[39m==\u001b[39m actual_label:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.training.example.Example' object has no attribute 'cats'"
     ]
    }
   ],
   "source": [
    "# Convert the test data to `Example` objects\n",
    "test_data = convert_df(test)\n",
    "test_examples = convert_to_example(test_data)\n",
    "\n",
    "# Use the model to predict the test data\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for example in test_examples:\n",
    "    # Use the model to predict the text\n",
    "    doc = nlp(example.text)\n",
    "    predicted_label = max(doc.cats, key=doc.cats.get)  # Get the label with the highest score\n",
    "\n",
    "    # Get the actual label\n",
    "    actual_label = max(example.cats, key=example.annotation.cats.get)\n",
    "    \n",
    "    # If the predicted label matches the actual label, increment correct_predictions\n",
    "    if predicted_label == actual_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "    total_predictions += 1\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {correct_predictions/total_predictions:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare the test data\n",
    "test_data = convert_df(test)\n",
    "test_examples = convert_to_example(test_data)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = [max(example.y.cats, key=example.y.cats.get) for example in test_examples]\n",
    "\n",
    "# Predict the labels with the model\n",
    "predicted_labels = []\n",
    "for example in test_examples:\n",
    "    doc = nlp(example.text)\n",
    "    predicted_labels.append(max(doc.cats, key=doc.cats.get))\n",
    "\n",
    "# Ensure the labels are in the same format\n",
    "true_labels = [str(label) for label in true_labels]\n",
    "predicted_labels = [str(label) for label in predicted_labels]\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels: ['2', '0', '0', '2', '1', '0', '1', '2', '2', '0']\n",
      "Predicted labels: ['Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low']\n"
     ]
    }
   ],
   "source": [
    "print(\"True labels:\", true_labels[:10]) \n",
    "print(\"Predicted labels:\", predicted_labels[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "\n",
    "from setfit import SetFitModel, SetFitTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/daaa/.cache/huggingface/datasets/csv/default-3ccb1e3336d246a2/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files=\"ticketClassification.csv\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'text', 'label'],\n",
       "    num_rows: 8469\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'text', 'label'],\n",
       "        num_rows: 6775\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'text', 'label'],\n",
       "        num_rows: 1694\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stratify_column_name = \"label\"\n",
    "\n",
    "dataset.class_encode_column(\n",
    "    stratify_column_name\n",
    ").train_test_split(\n",
    "    test_size=0.2, \n",
    "    stratify_by_column=stratify_column_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select N examples per class (8 in this case)\n",
    "# train_ds = dataset[\"train\"]\n",
    "# test_ds = dataset[\"test\"]\n",
    "\n",
    "split_data = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = split_data['train']\n",
    "test_ds = split_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 594/594 [00:00<00:00, 3.02MB/s]\n",
      "Downloading (…)f39ef/.gitattributes: 100%|██████████| 690/690 [00:00<00:00, 4.42MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 851kB/s]\n",
      "Downloading (…)0182ff39ef/README.md: 100%|██████████| 3.70k/3.70k [00:00<00:00, 17.5MB/s]\n",
      "Downloading (…)82ff39ef/config.json: 100%|██████████| 594/594 [00:00<00:00, 1.30MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 122/122 [00:00<00:00, 545kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 438M/438M [00:24<00:00, 17.8MB/s] \n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 241kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 934kB/s]\n",
      "Downloading (…)f39ef/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 728kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 1.19k/1.19k [00:00<00:00, 5.12MB/s]\n",
      "Downloading (…)0182ff39ef/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 538kB/s]\n",
      "Downloading (…)2ff39ef/modules.json: 100%|██████████| 229/229 [00:00<00:00, 1.10MB/s]\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load SetFit model from Hub\n",
    "model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    batch_size=16,\n",
    "    num_iterations=20, # Number of text pairs to generate for contrastive learning\n",
    "    num_epochs=1 # Number of epochs to use for contrastive learning\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Training Pairs: 100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 271000\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 16938\n",
      "  Total train batch size = 16\n",
      "Iteration:   3%|▎         | 478/16938 [25:04<14:23:29,  3.15s/it]\n",
      "Epoch:   0%|          | 0/1 [25:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train and evaluate!\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m      3\u001b[0m metrics \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/setfit/trainer.py:395\u001b[0m, in \u001b[0;36mSetFitTrainer.train\u001b[0;34m(self, num_epochs, batch_size, learning_rate, body_learning_rate, l2_weight, max_length, trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    392\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  Total train batch size = \u001b[39m\u001b[39m{\u001b[39;00mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    394\u001b[0m     warmup_steps \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mceil(total_train_steps \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarmup_proportion)\n\u001b[0;32m--> 395\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mmodel_body\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    396\u001b[0m         train_objectives\u001b[39m=\u001b[39;49m[(train_dataloader, train_loss)],\n\u001b[1;32m    397\u001b[0m         epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m    398\u001b[0m         optimizer_params\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m: learning_rate},\n\u001b[1;32m    399\u001b[0m         warmup_steps\u001b[39m=\u001b[39;49mwarmup_steps,\n\u001b[1;32m    400\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    401\u001b[0m         use_amp\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_amp,\n\u001b[1;32m    402\u001b[0m     )\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mhas_differentiable_head \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_freeze:\n\u001b[1;32m    405\u001b[0m     \u001b[39m# Train the final classifier\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(\n\u001b[1;32m    407\u001b[0m         x_train,\n\u001b[1;32m    408\u001b[0m         y_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m         show_progress_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    416\u001b[0m     )\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:721\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    719\u001b[0m     skip_scheduler \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mget_scale() \u001b[39m!=\u001b[39m scale_before_step\n\u001b[1;32m    720\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 721\u001b[0m     loss_value \u001b[39m=\u001b[39m loss_model(features, labels)\n\u001b[1;32m    722\u001b[0m     loss_value\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    723\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(loss_model\u001b[39m.\u001b[39mparameters(), max_grad_norm)\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sentence_transformers/losses/CosineSimilarityLoss.py:39\u001b[0m, in \u001b[0;36mCosineSimilarityLoss.forward\u001b[0;34m(self, sentence_features, labels)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, sentence_features: Iterable[Dict[\u001b[39mstr\u001b[39m, Tensor]], labels: Tensor):\n\u001b[0;32m---> 39\u001b[0m     embeddings \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(sentence_feature)[\u001b[39m'\u001b[39m\u001b[39msentence_embedding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m sentence_feature \u001b[39min\u001b[39;00m sentence_features]\n\u001b[1;32m     40\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcos_score_transformation(torch\u001b[39m.\u001b[39mcosine_similarity(embeddings[\u001b[39m0\u001b[39m], embeddings[\u001b[39m1\u001b[39m]))\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fct(output, labels\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sentence_transformers/losses/CosineSimilarityLoss.py:39\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, sentence_features: Iterable[Dict[\u001b[39mstr\u001b[39m, Tensor]], labels: Tensor):\n\u001b[0;32m---> 39\u001b[0m     embeddings \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(sentence_feature)[\u001b[39m'\u001b[39m\u001b[39msentence_embedding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m sentence_feature \u001b[39min\u001b[39;00m sentence_features]\n\u001b[1;32m     40\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcos_score_transformation(torch\u001b[39m.\u001b[39mcosine_similarity(embeddings[\u001b[39m0\u001b[39m], embeddings[\u001b[39m1\u001b[39m]))\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fct(output, labels\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[1;32m     64\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     67\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:550\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    549\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids\u001b[39m=\u001b[39minput_ids, position_ids\u001b[39m=\u001b[39mposition_ids, inputs_embeds\u001b[39m=\u001b[39minputs_embeds)\n\u001b[0;32m--> 550\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    551\u001b[0m     embedding_output,\n\u001b[1;32m    552\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    553\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    554\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    555\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    556\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    557\u001b[0m )\n\u001b[1;32m    558\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    559\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:339\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    337\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 339\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    340\u001b[0m     hidden_states,\n\u001b[1;32m    341\u001b[0m     attention_mask,\n\u001b[1;32m    342\u001b[0m     head_mask[i],\n\u001b[1;32m    343\u001b[0m     position_bias,\n\u001b[1;32m    344\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    345\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    346\u001b[0m )\n\u001b[1;32m    347\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    349\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:309\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add self attentions if we output attention weights\u001b[39;00m\n\u001b[1;32m    308\u001b[0m intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 309\u001b[0m layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[1;32m    310\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    311\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:277\u001b[0m, in \u001b[0;36mMPNetOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    276\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 277\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(hidden_states)\n\u001b[1;32m    278\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n\u001b[1;32m    279\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/Downloads/KAKI-App/venv/lib/python3.10/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train and evaluate!\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ticketClassification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"row_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical issue Product setup I'm having an is...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technical issue Peripheral compatibility I'm h...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Technical issue Network problem I'm facing a p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Billing inquiry Account access I'm having an i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Billing inquiry Data loss I'm having an issue ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8464</th>\n",
       "      <td>Product inquiry Installation support My {produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8465</th>\n",
       "      <td>Technical issue Refund request I'm having an i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8466</th>\n",
       "      <td>Technical issue Account access I'm having an i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8467</th>\n",
       "      <td>Product inquiry Payment issue I'm having an is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8468</th>\n",
       "      <td>Billing inquiry Hardware issue There seems to ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Technical issue Product setup I'm having an is...      3\n",
       "1     Technical issue Peripheral compatibility I'm h...      3\n",
       "2     Technical issue Network problem I'm facing a p...      0\n",
       "3     Billing inquiry Account access I'm having an i...      0\n",
       "4     Billing inquiry Data loss I'm having an issue ...      0\n",
       "...                                                 ...    ...\n",
       "8464  Product inquiry Installation support My {produ...      0\n",
       "8465  Technical issue Refund request I'm having an i...      3\n",
       "8466  Technical issue Account access I'm having an i...      2\n",
       "8467  Product inquiry Payment issue I'm having an is...      1\n",
       "8468  Billing inquiry Hardware issue There seems to ...      2\n",
       "\n",
       "[8469 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.2469310670443815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Assuming df is your DataFrame and 'text' and 'label' are the column names\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], random_state=42)\n",
    "\n",
    "# Create a pipeline to vectorize the data, then train and fit a model\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Train the classifier\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Test the classifier and display its accuracy score\n",
    "accuracy = text_clf.score(X_test, y_test)\n",
    "print(f\"Model accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.2516525023607177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Create a pipeline to vectorize the data, then train and fit a model\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Train the classifier\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Test the classifier and display its accuracy score\n",
    "accuracy = text_clf.score(X_test, y_test)\n",
    "print(f\"Model accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/daaa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/daaa/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize a Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function to handle all preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "    # Lemmatize the words\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "# Apply the preprocessing to each text in your DataFrame\n",
    "df['text'] = df['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.22      0.22       415\n",
      "           1       0.26      0.24      0.25       459\n",
      "           2       0.23      0.24      0.24       409\n",
      "           3       0.22      0.23      0.22       411\n",
      "\n",
      "    accuracy                           0.23      1694\n",
      "   macro avg       0.23      0.23      0.23      1694\n",
      "weighted avg       0.23      0.23      0.23      1694\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline that vectorizes the data, then trains and fits a model\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Train the classifier\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = text_clf.predict(X_test)\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.21      0.22       415\n",
      "           1       0.29      0.28      0.28       459\n",
      "           2       0.25      0.26      0.26       409\n",
      "           3       0.26      0.28      0.27       411\n",
      "\n",
      "    accuracy                           0.26      1694\n",
      "   macro avg       0.26      0.26      0.26      1694\n",
      "weighted avg       0.26      0.26      0.26      1694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a pipeline to vectorize the data, then train and fit a model\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(solver='liblinear')),\n",
    "])\n",
    "\n",
    "# Train the classifier\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = text_clf.predict(X_test)\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.23      0.24       415\n",
      "           1       0.29      0.28      0.29       459\n",
      "           2       0.24      0.26      0.25       409\n",
      "           3       0.25      0.26      0.26       411\n",
      "\n",
      "    accuracy                           0.26      1694\n",
      "   macro avg       0.26      0.26      0.26      1694\n",
      "weighted avg       0.26      0.26      0.26      1694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a pipeline to vectorize the data, then train and fit a model\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "# Train the classifier\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = text_clf.predict(X_test)\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'clf__C': 0.1, 'tfidf__use_idf': True}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.21      0.22       415\n",
      "           1       0.29      0.28      0.28       459\n",
      "           2       0.26      0.27      0.26       409\n",
      "           3       0.26      0.28      0.27       411\n",
      "\n",
      "    accuracy                           0.26      1694\n",
      "   macro avg       0.26      0.26      0.26      1694\n",
      "weighted avg       0.26      0.26      0.26      1694\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__C': (0.1, 1, 10),\n",
    "}\n",
    "\n",
    "# Create a pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(text_clf, param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.21      0.22       415\n",
      "           1       0.26      0.26      0.26       459\n",
      "           2       0.27      0.27      0.27       409\n",
      "           3       0.24      0.24      0.24       411\n",
      "\n",
      "    accuracy                           0.25      1694\n",
      "   macro avg       0.25      0.25      0.25      1694\n",
      "weighted avg       0.25      0.25      0.25      1694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline to vectorize the data, then train and fit a model\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')),\n",
    "])\n",
    "\n",
    "# Train the classifier\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = text_clf.predict(X_test)\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/8d/22/719f4fff33b13b0708711fb52ca3fc44617a26728e0e023358288d5197ae/matplotlib-3.7.2-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading matplotlib-3.7.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/15/c4/aae3954fce0e22362cc55430d1a395bf0be5a22b40fce63edda9eb6ea339/contourpy-1.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading contourpy-1.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.7 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/bf/22/3a8d523d4c97ee358e5259aa0c0812d912eec76828a0b374b5c57292fc60/fonttools-4.41.1-cp310-cp310-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading fonttools-4.41.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (150 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.0/150.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-macosx_11_0_arm64.whl (63 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from matplotlib) (10.0.0)\n",
      "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.7.2-cp310-cp310-macosx_11_0_arm64.whl (7.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.1.0-cp310-cp310-macosx_11_0_arm64.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.4/229.4 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fonttools-4.41.1-cp310-cp310-macosx_10_9_universal2.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.1.0\n",
      "    Uninstalling pyparsing-3.1.0:\n",
      "      Successfully uninstalled pyparsing-3.1.0\n",
      "Successfully installed contourpy-1.1.0 cycler-0.11.0 fonttools-4.41.1 kiwisolver-1.4.4 matplotlib-3.7.2 pyparsing-3.0.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "label\n",
      "1    2192\n",
      "3    2129\n",
      "2    2085\n",
      "0    2063\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the value counts of the 'label' column\n",
    "class_counts = df['label'].value_counts()\n",
    "\n",
    "# Print the class counts\n",
    "print(class_counts)\n",
    "\n",
    "# Plot the class counts\n",
    "plt.figure(figsize=(10,5))\n",
    "class_counts.plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'clf__learning_rate': 0.1, 'clf__max_depth': 3, 'clf__n_estimators': 50}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.12      0.16       415\n",
      "           1       0.27      0.40      0.33       459\n",
      "           2       0.27      0.21      0.24       409\n",
      "           3       0.21      0.27      0.24       411\n",
      "\n",
      "    accuracy                           0.25      1694\n",
      "   macro avg       0.25      0.25      0.24      1694\n",
      "weighted avg       0.25      0.25      0.24      1694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [50, 100],  # Reduced number of trees\n",
    "    'clf__max_depth': [3, 5],  # Reduced max depth\n",
    "    'clf__learning_rate': [0.1],  # Only one learning rate\n",
    "}\n",
    "\n",
    "# Create a pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(use_idf=True)),  # Only use IDF\n",
    "    ('clf', xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', subsample=1, colsample_bytree=1)),  # Set subsample and colsample_bytree to 1\n",
    "])\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(text_clf, param_grid, cv=2, n_jobs=-1)  # Reduced CV folds\n",
    "\n",
    "# Fit the GridSearchCV object\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Create a Doc object\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Generate lemmas\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    \n",
    "    # Remove stopwords and non-alphabetic characters\n",
    "    a_lemmas = [lemma for lemma in lemmas \n",
    "            if lemma.isalpha() and lemma not in nlp.Defaults.stop_words]\n",
    "    \n",
    "    # Return preprocessed list of tokens\n",
    "    return ' '.join(a_lemmas)\n",
    "\n",
    "# Apply preprocessing to the text column\n",
    "df['text'] = df['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at iteration 0 - {'textcat': 195.7870711684227}\n",
      "Losses at iteration 1 - {'textcat': 194.36518259346485}\n",
      "Losses at iteration 2 - {'textcat': 185.678729750216}\n",
      "Losses at iteration 3 - {'textcat': 160.92434392124414}\n",
      "Losses at iteration 4 - {'textcat': 131.7278599087149}\n",
      "Losses at iteration 5 - {'textcat': 108.90524978991016}\n",
      "Losses at iteration 6 - {'textcat': 92.11912235555064}\n",
      "Losses at iteration 7 - {'textcat': 78.28992322046497}\n",
      "Losses at iteration 8 - {'textcat': 68.59683896085727}\n",
      "Losses at iteration 9 - {'textcat': 61.993924266661665}\n",
      "Losses at iteration 10 - {'textcat': 57.14530249284654}\n",
      "Losses at iteration 11 - {'textcat': 50.806975998621546}\n",
      "Losses at iteration 12 - {'textcat': 49.704976212866384}\n",
      "Losses at iteration 13 - {'textcat': 46.27049130601455}\n",
      "Losses at iteration 14 - {'textcat': 42.4917293401703}\n",
      "Losses at iteration 15 - {'textcat': 42.37906326067315}\n",
      "Losses at iteration 16 - {'textcat': 38.20284542011896}\n",
      "Losses at iteration 17 - {'textcat': 37.841543373716746}\n",
      "Losses at iteration 18 - {'textcat': 36.059575928682825}\n",
      "Losses at iteration 19 - {'textcat': 35.68458426924519}\n",
      "Losses at iteration 20 - {'textcat': 33.17162532916906}\n",
      "Losses at iteration 21 - {'textcat': 32.052025933273775}\n",
      "Losses at iteration 22 - {'textcat': 32.52118338023546}\n",
      "Losses at iteration 23 - {'textcat': 31.93573158560683}\n",
      "Losses at iteration 24 - {'textcat': 29.116039190166788}\n",
      "Losses at iteration 25 - {'textcat': 31.57792883020163}\n",
      "Losses at iteration 26 - {'textcat': 29.635027851696826}\n",
      "Losses at iteration 27 - {'textcat': 27.20423533323975}\n",
      "Losses at iteration 28 - {'textcat': 26.74488424293323}\n",
      "Losses at iteration 29 - {'textcat': 26.370591317423642}\n",
      "Accuracy: 0.2396694214876033\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training import Example\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load a blank English model\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "# Add a text classifier to the pipeline\n",
    "textcat = nlp.add_pipe('textcat')\n",
    "\n",
    "# Add labels to the text classifier\n",
    "for label in df['label'].unique():\n",
    "    textcat.add_label(str(label))  # Ensure the label is a string\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the training data into the format required by spaCy\n",
    "train_data = [Example.from_dict(nlp.make_doc(text), {'cats': {str(label): str(label) == str(y) for label in textcat.labels}}) for text, y in zip(X_train, y_train)]  # Create Example objects\n",
    "\n",
    "# Initialize the model with the training data\n",
    "nlp.initialize(lambda: train_data)\n",
    "\n",
    "# Train the model\n",
    "n_iter = 30\n",
    "for i in range(n_iter):\n",
    "    losses = {}\n",
    "    batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "    for batch in batches:\n",
    "        nlp.update(batch, losses=losses)\n",
    "    print(f\"Losses at iteration {i} - {losses}\")\n",
    "\n",
    "# Test the model\n",
    "correct_predictions = 0\n",
    "for doc, y in zip(X_test, y_test):\n",
    "    doc = nlp(doc)\n",
    "    predicted_label = max(doc.cats, key=doc.cats.get)\n",
    "    if predicted_label == str(y):  # Ensure the label is a string\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {correct_predictions / len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>technical issue product setup im issue product...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>technical issue peripheral compatibility im is...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>technical issue network problem im facing prob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>billing inquiry account access im issue produc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>billing inquiry data loss im issue productpurc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8464</th>\n",
       "      <td>product inquiry installation support productpu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8465</th>\n",
       "      <td>technical issue refund request im issue produc...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8466</th>\n",
       "      <td>technical issue account access im issue produc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8467</th>\n",
       "      <td>product inquiry payment issue im issue product...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8468</th>\n",
       "      <td>billing inquiry hardware issue seems hardware ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     technical issue product setup im issue product...      3\n",
       "1     technical issue peripheral compatibility im is...      3\n",
       "2     technical issue network problem im facing prob...      0\n",
       "3     billing inquiry account access im issue produc...      0\n",
       "4     billing inquiry data loss im issue productpurc...      0\n",
       "...                                                 ...    ...\n",
       "8464  product inquiry installation support productpu...      0\n",
       "8465  technical issue refund request im issue produc...      3\n",
       "8466  technical issue account access im issue produc...      2\n",
       "8467  product inquiry payment issue im issue product...      1\n",
       "8468  billing inquiry hardware issue seems hardware ...      2\n",
       "\n",
       "[8469 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>technical issue product setup I m issue produc...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>technical issue peripheral compatibility I m i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>technical issue network problem I m face probl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bill inquiry account access I m issue productp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bill inquiry datum loss I m issue productpurch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  technical issue product setup I m issue produc...       3\n",
       "1  technical issue peripheral compatibility I m i...       3\n",
       "2  technical issue network problem I m face probl...       0\n",
       "3  bill inquiry account access I m issue productp...       0\n",
       "4  bill inquiry datum loss I m issue productpurch...       0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={\"label\": \"target\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ticketClassifierV2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to summarize, SCREW THIS SHIT LETS TRY HF AUTOTRAIN\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
