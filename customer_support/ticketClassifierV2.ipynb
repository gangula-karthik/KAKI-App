{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "from spacy.util import minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/daaa/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ticketClassification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Technical issue Product setup I'm having an is...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Technical issue Peripheral compatibility I'm h...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Technical issue Network problem I'm facing a p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Billing inquiry Account access I'm having an i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Billing inquiry Data loss I'm having an issue ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  label\n",
       "0           0  Technical issue Product setup I'm having an is...      3\n",
       "1           1  Technical issue Peripheral compatibility I'm h...      3\n",
       "2           2  Technical issue Network problem I'm facing a p...      0\n",
       "3           3  Billing inquiry Account access I'm having an i...      0\n",
       "4           4  Billing inquiry Data loss I'm having an issue ...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Technical issue Product setup I'm having an is...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    2192\n",
       "3    2129\n",
       "2    2085\n",
       "0    2063\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts() # dataset is balanced :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df(df):\n",
    "    return df.apply(lambda row: (row['text'], {\"cats\": {row['label']: 1}}), axis=1).tolist()\n",
    "\n",
    "train_data = convert_df(train)\n",
    "test_data = convert_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n",
      "Losses {'textcat': 58.0625}\n"
     ]
    }
   ],
   "source": [
    "from spacy.training import Example\n",
    "\n",
    "def convert_to_example(df):\n",
    "    examples = []\n",
    "    for text, annot in df:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, annot)\n",
    "        examples.append(example)\n",
    "    return examples\n",
    "\n",
    "train_data = convert_df(train)\n",
    "train_examples = convert_to_example(train_data)\n",
    "\n",
    "# Start training\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "for i in range(10):\n",
    "    losses = {}\n",
    "    batches = minibatch(train_examples, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        nlp.update(batch, sgd=optimizer, drop=0.2, losses=losses)\n",
    "    print(\"Losses\", losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.training.example.Example' object has no attribute 'cats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m predicted_label \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(doc\u001b[39m.\u001b[39mcats, key\u001b[39m=\u001b[39mdoc\u001b[39m.\u001b[39mcats\u001b[39m.\u001b[39mget)  \u001b[39m# Get the label with the highest score\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# Get the actual label\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m actual_label \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(example\u001b[39m.\u001b[39;49mcats, key\u001b[39m=\u001b[39mexample\u001b[39m.\u001b[39mannotation\u001b[39m.\u001b[39mcats\u001b[39m.\u001b[39mget)\n\u001b[1;32m     17\u001b[0m \u001b[39m# If the predicted label matches the actual label, increment correct_predictions\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m predicted_label \u001b[39m==\u001b[39m actual_label:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.training.example.Example' object has no attribute 'cats'"
     ]
    }
   ],
   "source": [
    "# Convert the test data to `Example` objects\n",
    "test_data = convert_df(test)\n",
    "test_examples = convert_to_example(test_data)\n",
    "\n",
    "# Use the model to predict the test data\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for example in test_examples:\n",
    "    # Use the model to predict the text\n",
    "    doc = nlp(example.text)\n",
    "    predicted_label = max(doc.cats, key=doc.cats.get)  # Get the label with the highest score\n",
    "\n",
    "    # Get the actual label\n",
    "    actual_label = max(example.cats, key=example.annotation.cats.get)\n",
    "    \n",
    "    # If the predicted label matches the actual label, increment correct_predictions\n",
    "    if predicted_label == actual_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "    total_predictions += 1\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {correct_predictions/total_predictions:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare the test data\n",
    "test_data = convert_df(test)\n",
    "test_examples = convert_to_example(test_data)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = [max(example.y.cats, key=example.y.cats.get) for example in test_examples]\n",
    "\n",
    "# Predict the labels with the model\n",
    "predicted_labels = []\n",
    "for example in test_examples:\n",
    "    doc = nlp(example.text)\n",
    "    predicted_labels.append(max(doc.cats, key=doc.cats.get))\n",
    "\n",
    "# Ensure the labels are in the same format\n",
    "true_labels = [str(label) for label in true_labels]\n",
    "predicted_labels = [str(label) for label in predicted_labels]\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels: ['2', '0', '0', '2', '1', '0', '1', '2', '2', '0']\n",
      "Predicted labels: ['Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low']\n"
     ]
    }
   ],
   "source": [
    "print(\"True labels:\", true_labels[:10]) \n",
    "print(\"Predicted labels:\", predicted_labels[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
