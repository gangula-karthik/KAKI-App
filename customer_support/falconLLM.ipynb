{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain import PromptTemplate, LLMChain, OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 2\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "HUGGINGFACEHUB_API_TOKEN = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"tiiuae/falcon-7b-instruct\"  # See https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads for some other options\n",
    "falcon_llm = HuggingFaceHub(\n",
    "    repo_id=repo_id, model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 500}, huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=falcon_llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Check your order history on Amazon.\n",
      "2. Look for the order you want to return.\n",
      "3. Click on the\n",
      "order to open it.\n",
      "4. Click on the \"Return or Replace Items\" button.\n",
      "5. Follow the on-screen\n",
      "instructions to complete the return process.\n",
      "6. Once your return is processed, you will receive a\n",
      "refund.\n",
      "\n",
      "Note: The refund amount may vary depending on the product and the reason for the return.\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I get a refund on amazon\"\n",
    "response = llm_chain.run(question)\n",
    "wrapped_text = textwrap.fill(\n",
    "    response, width=100, break_long_words=False, replace_whitespace=False\n",
    ")\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: transformers in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (4.30.1)\n",
      "Requirement already satisfied: filelock in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 4.60k/4.60k [00:00<00:00, 5.68MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 288kB/s]\n",
      "Downloading (…)_tokenizer/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 9.55MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 714kB/s]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 148kB/s]\n",
      "Downloading (…)tokenizer/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 1.44MB/s]\n",
      "Downloading (…)tokenizer/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 63.2MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 772/772 [00:00<00:00, 3.04MB/s]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "Downloading builder script: 100%|██████████| 9.62k/9.62k [00:00<00:00, 6.06MB/s]\n",
      "Downloading metadata: 100%|██████████| 67.5k/67.5k [00:00<00:00, 30.2MB/s]\n",
      "Downloading readme: 100%|██████████| 14.6k/14.6k [00:00<00:00, 6.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wiki_dpr/dummy.psgs_w100.nq.no_index to /Users/daaa/.cache/huggingface/datasets/wiki_dpr/dummy.psgs_w100.nq.no_index-dummy=True,with_index=False/0.0.0/74d4bff38a7c18a9498fafef864a8ba7129e27cb8d71b22f5e14d84cb17edd54...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 4.69G/4.69G [01:04<00:00, 72.8MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [01:04<00:00, 64.60s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [01:04<00:00, 64.94s/it]\n",
      "Downloading data: 100%|██████████| 1.32G/1.32G [00:19<00:00, 69.5MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:19<00:00, 19.95s/it]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wiki_dpr downloaded and prepared to /Users/daaa/.cache/huggingface/datasets/wiki_dpr/dummy.psgs_w100.nq.no_index-dummy=True,with_index=False/0.0.0/74d4bff38a7c18a9498fafef864a8ba7129e27cb8d71b22f5e14d84cb17edd54. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset wiki_dpr/dummy.psgs_w100.nq.exact to /Users/daaa/.cache/huggingface/datasets/wiki_dpr/dummy.psgs_w100.nq.exact-ce970d5f816ae529/0.0.0/74d4bff38a7c18a9498fafef864a8ba7129e27cb8d71b22f5e14d84cb17edd54...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 807.68it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 382.73it/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 2158.67it/s]\n",
      "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wiki_dpr downloaded and prepared to /Users/daaa/.cache/huggingface/datasets/wiki_dpr/dummy.psgs_w100.nq.exact-ce970d5f816ae529/0.0.0/74d4bff38a7c18a9498fafef864a8ba7129e27cb8d71b22f5e14d84cb17edd54. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.70it/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 2.06G/2.06G [00:27<00:00, 74.8MB/s]\n",
      "Some weights of the model checkpoint at facebook/rag-sequence-nq were not used when initializing RagSequenceForGeneration: ['rag.question_encoder.question_encoder.bert_model.pooler.dense.bias', 'rag.question_encoder.question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RagSequenceForGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RagSequenceForGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RagSequenceForGeneration were not initialized from the model checkpoint at facebook/rag-sequence-nq and are newly initialized: ['rag.generator.lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-sequence-nq\")\n",
    "retriever = RagRetriever.from_pretrained(\"facebook/rag-sequence-nq\", index_name=\"exact\", use_dummy_dataset=True)\n",
    "model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-sequence-nq\", retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/transformers/models/rag/tokenization_rag.py:87: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_dict = tokenizer.prepare_seq2seq_batch(\"What is the capital of France?\", return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2054, 2003, 1996, 3007, 1997, 2605, 1029,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daaa/Downloads/KAKI-App/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "generated = model.generate(input_ids=input_dict[\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2, 475,   2,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated\n",
    "\n",
    "# response = tokenizer.batch_decode(generated, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tokenizer.batch_decode(generated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' m']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import JSONLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
